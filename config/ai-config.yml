ai:
  # LLM Configuration
  llm:
    provider: "openai"  # openai, anthropic, local
    model: "gpt-4"
    api_key: "${OPENAI_API_KEY}"
    temperature: 0.1
    max_tokens: 2048
    timeout: 30

  # Embedding Configuration
  embeddings:
    provider: "openai"  # openai, sentence-transformers, local
    model: "text-embedding-ada-002"
    dimension: 1536
    batch_size: 100

  # Vector Database Configuration
  vector_db:
    provider: "qdrant"
    url: "http://qdrant:6333"
    collection_name: "observability_data"
    distance_metric: "cosine"

# Data Processing Configuration
data_processing:
  # Metrics Processing
  metrics:
    aggregation_window: "5m"
    retention_period: "7d"
    anomaly_detection:
      enabled: true
      sensitivity: 0.8
      min_samples: 100
    
    important_metrics:
      - "cpu_usage_percent"
      - "memory_usage_percent"
      - "disk_usage_percent"
      - "network_bytes_total"
      - "http_request_duration"
      - "http_requests_total"
      - "error_rate"
      - "response_time"

  # Logs Processing
  logs:
    parsing:
      enabled: true
      extract_structured: true
      severity_detection: true
    
    filtering:
      exclude_patterns:
        - "health-check"
        - "ping"
        - "metrics"
      
      include_severity:
        - "ERROR"
        - "WARN"
        - "FATAL"
    
    clustering:
      enabled: true
      similarity_threshold: 0.85
      max_clusters: 1000

  # Traces Processing
  traces:
    sampling_rate: 0.1
    error_traces_sampling_rate: 1.0
    slow_traces_threshold: "1s"
    
    analysis:
      dependency_mapping: true
      bottleneck_detection: true
      error_propagation: true

# AI Analysis Configuration
analysis:
  # Performance Analysis
  performance:
    metrics_correlation: true
    trend_analysis: true
    capacity_planning: true
    sla_monitoring: true
    
    thresholds:
      cpu_high: 80
      memory_high: 85
      disk_high: 90
      response_time_high: 2000  # ms
      error_rate_high: 5  # percent

  # Anomaly Detection
  anomaly_detection:
    algorithms:
      - "isolation_forest"
      - "local_outlier_factor"
      - "one_class_svm"
    
    sensitivity: 0.1
    min_anomaly_score: 0.5
    correlation_window: "1h"

  # Root Cause Analysis
  root_cause:
    enabled: true
    correlation_threshold: 0.7
    time_window: "15m"
    max_depth: 5

# Chat Interface Configuration
chat:
  # Response Configuration
  response:
    max_length: 1000
    include_charts: true
    include_metrics: true
    include_recommendations: true
  
  # Query Processing
  query_processing:
    intent_classification: true
    entity_extraction: true
    context_window: 10  # number of previous messages
  
  # Predefined Queries
  quick_queries:
    - "Show me system performance overview"
    - "What are the current issues?"
    - "Analyze recent errors"
    - "Show me slow requests"
    - "Performance trends in the last hour"
    - "Resource utilization summary"

# Data Sources Configuration
data_sources:
  prometheus:
    url: "http://prometheus:9090"
    timeout: 30
    max_points: 10000
  
  elasticsearch:
    url: "http://elasticsearch:9200"
    timeout: 30
    max_results: 1000
    indices:
      logs: "observability-logs"
      traces: "observability-traces"
  
  jaeger:
    url: "http://jaeger:16686"
    timeout: 30
    max_traces: 100

# Caching Configuration
cache:
  redis:
    enabled: false
    url: "redis://redis:6379"
  
  memory:
    enabled: true
    max_size_mb: 512
    ttl_seconds: 300

# Monitoring and Logging
monitoring:
  metrics_port: 5001
  health_check_port: 5002
  log_level: "INFO"
  
  telemetry:
    enabled: true
    export_interval: "30s"